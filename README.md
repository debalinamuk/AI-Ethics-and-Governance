AI Ethics and Governance

📌 Project Overview  
This project was completed as part of PHL6001: AI Ethics & Governance.  
The task simulated a consulting report for a joint White House and Congressional task force, with the goal of developing governance recommendations for artificial intelligence.
The report and presentation:
1.	Identify central ethical challenges posed by AI.
2.	Propose governance and regulatory frameworks to address them.
3.	Engage critically with course readings to support recommendations.

🎯 Ethical Challenges Identified
1.	Bias in Algorithms
⦁	Example: Zip code data can unintentionally discriminate in lending, hiring, and healthcare.
⦁	Risk: Reinforces systemic inequalities.
2.	Data Privacy & Commodification
⦁	Concern: Widespread collection and monetization of personal data.
⦁	Tension: Autonomy vs. market exchange.
3.	Algorithmic Opacity (“Black Box” AI)
⦁	Challenge: Lack of explainability in decision-making systems.
⦁	Impact: Reduced accountability and public trust.

📚 Course Readings and References  
At least three readings were used to contextualize, support, or critique governance approaches:
⦁	Fazelpour – On ensuring fairness and amplifying marginalized voices.
⦁	Zuboff – On the risks of surveillance capitalism and data commodification.
⦁	Rini – On protecting shared truth in the face of algorithmic manipulation.
These works provided the theoretical foundation for the recommendations.

⚖️ Competing Values at Stake
⦁	Innovation vs. Regulation – Encouraging progress without stifling creativity.
⦁	Autonomy vs. Market Forces – Data as voluntary exchange vs. violation of privacy.
⦁	Efficiency vs. Transparency – Fast AI decision-making vs. explainability for accountability.

🏛 Governance Options Considered
1.	Voluntary Industry Guidelines
⦁	Pro: Flexible, adaptable.
⦁	Con: Lack of enforcement, risk of “ethics-washing.
2.	Government Regulation
⦁	Pro: Legal accountability, public trust.
⦁	Con: May slow innovation, bureaucratic delays.
3.	Hybrid Models (Public-Private Collaboration)
⦁	Pro: Balanced approach, shared responsibility.
⦁	Con: Requires strong oversight and cooperation.

✅ Recommendations  
The most balanced option was a hybrid governance framework:
⦁	Independent auditing of AI systems.
⦁	Transparency and explainability requirements.
⦁	Stronger data privacy protections.
⦁	Public-private collaboration to balance innovation with accountability.
Conclusion: Responsible AI is not simply about compliance—it is essential for trust, fairness, and sustainable growth.

📑 Contents
⦁	Slides (PPT/PDF): Ethical issues, governance options, and final recommendations.
⦁	Recording (Video): 10 minute presentation.
⦁	README.md: Project description (this file).

🎥 Presentation Recording  
👉

📬 Contact  
Debalina Mukhopadhyay
🔗 LinkedIn Profile](https://www.linkedin.com/in/debalinamukhopadhyay/
📧 debalina1239@gmail.com
